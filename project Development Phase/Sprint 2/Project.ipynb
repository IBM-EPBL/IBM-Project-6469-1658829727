{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d54ede38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a1121e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1.255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_datagen=ImageDataGenerator(rescale=1.255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e220d08f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4118 images belonging to 5 classes.\n",
      "Found 1055 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'D:\\IBM\\Project\\dataset\\TRAIN_SET-20221029T100610Z-001\\TRAIN_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
    "x_test = train_datagen.flow_from_directory(r'D:\\IBM\\Project\\dataset\\TEST_SET-20221029T084343Z-001\\TEST_SET',target_size=(64,64),batch_size=5,color_mode='rgb',class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ff1ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print (x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6462fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_test.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f25378ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 995, 1: 1354, 2: 1019, 3: 275, 4: 475})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train . labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82d84cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1065e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e5aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a011adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef730460",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebb9d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(32,(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fed01ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "364bd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b91a95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128,activation='relu'))\n",
    "classifier.add(Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c0d1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 813,733\n",
      "Trainable params: 813,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "489161ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2976d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsmoh\\AppData\\Local\\Temp\\ipykernel_12248\\2842017323.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "824/824 [==============================] - 83s 100ms/step - loss: 2.8277 - accuracy: 0.5823 - val_loss: 1.2696 - val_accuracy: 0.5915\n",
      "Epoch 2/20\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.7678 - accuracy: 0.6591 - val_loss: 1.6754 - val_accuracy: 0.5744\n",
      "Epoch 3/20\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.7024 - accuracy: 0.6938 - val_loss: 2.5681 - val_accuracy: 0.5469\n",
      "Epoch 4/20\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.6612 - accuracy: 0.7013 - val_loss: 2.5845 - val_accuracy: 0.5953\n",
      "Epoch 5/20\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.6642 - accuracy: 0.7149 - val_loss: 0.8035 - val_accuracy: 0.7640\n",
      "Epoch 6/20\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.6364 - accuracy: 0.7319 - val_loss: 0.9733 - val_accuracy: 0.7308\n",
      "Epoch 7/20\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.5632 - accuracy: 0.7768 - val_loss: 1.0861 - val_accuracy: 0.7773\n",
      "Epoch 8/20\n",
      "824/824 [==============================] - 24s 29ms/step - loss: 0.5695 - accuracy: 0.7863 - val_loss: 1.1020 - val_accuracy: 0.7403\n",
      "Epoch 9/20\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.5655 - accuracy: 0.8026 - val_loss: 1.6008 - val_accuracy: 0.6986\n",
      "Epoch 10/20\n",
      "824/824 [==============================] - 25s 30ms/step - loss: 0.4539 - accuracy: 0.8293 - val_loss: 0.5954 - val_accuracy: 0.8389\n",
      "Epoch 11/20\n",
      "824/824 [==============================] - 26s 31ms/step - loss: 0.4640 - accuracy: 0.8327 - val_loss: 0.7620 - val_accuracy: 0.7678\n",
      "Epoch 12/20\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.4679 - accuracy: 0.8242 - val_loss: 2.2159 - val_accuracy: 0.7071\n",
      "Epoch 13/20\n",
      "824/824 [==============================] - 28s 33ms/step - loss: 0.4320 - accuracy: 0.8441 - val_loss: 1.9061 - val_accuracy: 0.7393\n",
      "Epoch 14/20\n",
      "824/824 [==============================] - 28s 33ms/step - loss: 0.4344 - accuracy: 0.8536 - val_loss: 1.4278 - val_accuracy: 0.7659\n",
      "Epoch 15/20\n",
      "824/824 [==============================] - 28s 34ms/step - loss: 0.3832 - accuracy: 0.8618 - val_loss: 0.6837 - val_accuracy: 0.8313\n",
      "Epoch 16/20\n",
      "824/824 [==============================] - 28s 34ms/step - loss: 0.4087 - accuracy: 0.8504 - val_loss: 2.7306 - val_accuracy: 0.7355\n",
      "Epoch 17/20\n",
      "824/824 [==============================] - 28s 34ms/step - loss: 0.3899 - accuracy: 0.8630 - val_loss: 1.9046 - val_accuracy: 0.7460\n",
      "Epoch 18/20\n",
      "824/824 [==============================] - 28s 34ms/step - loss: 0.5179 - accuracy: 0.8264 - val_loss: 0.8475 - val_accuracy: 0.7109\n",
      "Epoch 19/20\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.3562 - accuracy: 0.8652 - val_loss: 1.2132 - val_accuracy: 0.7782\n",
      "Epoch 20/20\n",
      "824/824 [==============================] - 27s 33ms/step - loss: 0.3336 - accuracy: 0.8825 - val_loss: 3.4507 - val_accuracy: 0.7517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef2d3b2be0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "    generator=x_train,steps_per_epoch=len(x_train),\n",
    "    epochs=20,validation_data=x_test,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00c507c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa04e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "model = load_model('nutrition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "311dbe1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2652\\798610245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m img = image.load_img(r\"D:\\IBM\\TEST_SET-20221029T084343Z-001\\TEST_SET\\BANANA\\12_100.jpg\",\n\u001b[0m\u001b[0;32m      2\u001b[0m                     target_size(64,64))\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexapand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "img = image.load_img(r\"D:\\IBM\\TEST_SET-20221029T084343Z-001\\TEST_SET\\BANANA\\12_100.jpg\",\n",
    "                    target_size(64,64))\n",
    "x = image.img_to_array(img)\n",
    "x = np.exapand_dims(x,axis=0)\n",
    "pred = model.predict_classes(x)\n",
    "pred\n",
    "index=['APPLES', 'BANANA', 'ORANGE', 'PINEAPPLE', 'WATERMELON']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a4322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d691d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
